import os
import Misc

# general
MODEL_NAME = 'DDQN_MNIST_DENSE'
USE_STOPSWITCH = True
PRINT_FREQ = 100

# RL training
BATCH_SIZE = 16
C = 2000
RL_UPDATES_PER_ENV_UPDATE = 1
MEMORY_CAP = 100000 # 100k

# Env config
SAMPLE_SIZE = 1
DATAPOINTS_TO_AVRG = 1
BUDGET = 1000 # MNIST
#BUDGET = 30 #IRIS
GAME_LENGTH = BUDGET
MAX_INTERACTIONS_PER_GAME = BUDGET * 5 / DATAPOINTS_TO_AVRG
REWARD_SCALE = 1#40
REWARD_SHAPING = False
LABEL_COST = 0.01
INIT_POINTS_PER_CLASS = 5

# training loop
MIN_INTERACTIONS = 500000
WARMUP = int(0.03*MIN_INTERACTIONS)
N_EXPLORE, N_CONVERSION = WARMUP + int(0.2*MIN_INTERACTIONS), int(0.4*MIN_INTERACTIONS)
EVAL_ITERATIONS = 4

GREED = Misc.parameterPlan(1, 0.001, warmup=N_EXPLORE, conversion=N_CONVERSION)
LR = Misc.parameterPlan(0.002, 0.0001, warmup=N_EXPLORE, conversion=N_CONVERSION)
GL = Misc.parameterPlan(3, BUDGET, warmup=WARMUP + int(0.1*MIN_INTERACTIONS), conversion=int(0.5*MIN_INTERACTIONS))

# file paths
OUTPUT_FOLDER = 'out'+MODEL_NAME
os.makedirs(OUTPUT_FOLDER, exist_ok=True)
memDir = os.path.join(OUTPUT_FOLDER, 'memory')
cacheDir = os.path.join(OUTPUT_FOLDER, 'cache')
ckptDir = os.path.join(cacheDir, 'ckpt')